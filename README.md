# Document Query Answering System

This project is a chatbot designed to answer questions based on document contents. The system uses embeddings and an LLM (Large Language Model) to retrieve the most relevant information from a set of documents and generate responses. It is implemented using Python, Streamlit for the web interface, and integrates with Groq for LLM responses.

## Features

- Extracts text from PDFs using OCR when necessary.
- Generates sentence embeddings for document pages to enable semantic search.
- Retrieves the most relevant document pages based on a user query.
- Uses an LLM to generate context-based answers from retrieved documents.

## Directory Structure

- **chatbot.py**: Main Streamlit application for the chatbot.
- **retrieval.py**: Handles document retrieval and answer generation based on query embeddings.
- **ingest_and_process.py**: Processes PDF documents, extracting text and applying OCR.
- **embedding.py**: Generates embeddings for each document page for similarity search.

## Requirements

- Python 3.7+
- Streamlit
- Sentence Transformers for embeddings
- Groq API key for LLM responses
- pdf2image and PyPDF2 for PDF processing
- pytesseract for OCR (if required)

## Setup

1. **Clone the Repository:**

    ```bash
    git clone https://github.com/username/repository-name.git
    cd repository-name
    ```

2. **Install Dependencies:** Create a virtual environment and install the necessary packages:

    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

3. **Set Up Environment Variables:** Add your Groq API key to a `.env` file or export it in the terminal:

    ```bash
    export GROQ_API_KEY="your_groq_api_key"
    ```

4. **Run the Application:** Start the Streamlit application:

    ```bash
    streamlit run chatbot.py
    ```

## Usage

1. Place your PDF documents in a `data/` directory within the project.
2. Open the Streamlit interface and enter a question related to the documents.
3. The system will retrieve the most relevant document page and generate an answer based on its content.

## Code Overview

- **chatbot.py**: Initializes and runs the Streamlit interface, loads models, and handles user queries.
- **retrieval.py**: Contains functions for finding the most similar document page and generating an answer based on LLM responses.
- **ingest_and_process.py**: Reads PDFs, extracts text, and applies OCR if text is not directly extractable.
- **embedding.py**: Generates embeddings for each document page to enable semantic similarity searches.

## Example

1. Run the app.
2. Upload your PDFs to `data/`.
3. Type a question in the text input box.
4. The system processes your query, finds the most relevant document, and provides an answer generated by the LLM.

## Contributing

1. Fork the repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Commit your changes (`git commit -am 'Add new feature'`).
4. Push the branch (`git push origin feature-branch`).
5. Open a pull request.
